{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa3e5451",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/aeoranday/SSI_Projects/blob/connect-first/if_projects/Lost-Edge-Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "raw",
   "id": "734740e0-29e2-4cc4-a0ef-adf19a5cd767",
   "metadata": {
    "id": "734740e0-29e2-4cc4-a0ef-adf19a5cd767"
   },
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/aeoranday/SSI_Projects/blob/connect-first/if_projects/Lost-Edge-Classification.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba799f23-6bcd-46c8-b910-a0e1555ad9d9",
   "metadata": {
    "id": "ba799f23-6bcd-46c8-b910-a0e1555ad9d9"
   },
   "source": [
    "# IF2 Lost Edge Classification\n",
    "Using the data from the SSI IF2 project, classify the edges that need to be connect and those that need to be disconnected. This is then a binary procedure where a 1 indicates that the edges should be connected and a 0 indicates that the edges should not be connected. In this case, it is best to start with a fully connected graph so that it may score each edge appropriately and does not assume that any particular edge is inherently disconnected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad9e41b-394f-4da3-b83a-ade731e0b4c5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0ad9e41b-394f-4da3-b83a-ade731e0b4c5",
    "outputId": "0c4a18b6-7a47-4ae8-e84e-2014fc3d109d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/drinkingkazu/ssi_if\n",
      "  Cloning https://github.com/drinkingkazu/ssi_if to /tmp/pip-req-build-4csb965y\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/drinkingkazu/ssi_if /tmp/pip-req-build-4csb965y\n",
      "  Resolved https://github.com/drinkingkazu/ssi_if to commit af38e2ce0730ec5a3091a849bee9e8e53d58042d\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (4.6.6)\n",
      "Collecting fire (from iftools==0.1)\n",
      "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (3.9.0)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (2.0.1+cu118)\n",
      "Collecting torch_geometric (from iftools==0.1)\n",
      "  Downloading torch_geometric-2.3.1.tar.gz (661 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.6/661.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (5.15.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from iftools==0.1) (3.7.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->iftools==0.1) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->iftools==0.1) (2.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown->iftools==0.1) (3.12.2)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown->iftools==0.1) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown->iftools==0.1) (4.66.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown->iftools==0.1) (4.11.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from h5py->iftools==0.1) (1.23.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (4.42.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->iftools==0.1) (2.8.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->iftools==0.1) (8.2.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (4.7.1)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (3.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->iftools==0.1) (2.0.0)\n",
      "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->iftools==0.1) (3.27.1)\n",
      "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->iftools==0.1) (16.0.6)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric->iftools==0.1) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric->iftools==0.1) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric->iftools==0.1) (5.9.5)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown->iftools==0.1) (2.4.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->iftools==0.1) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->iftools==0.1) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->iftools==0.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->iftools==0.1) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->iftools==0.1) (2023.7.22)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown->iftools==0.1) (1.7.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->iftools==0.1) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric->iftools==0.1) (3.2.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->iftools==0.1) (1.3.0)\n",
      "Building wheels for collected packages: iftools, fire, torch_geometric\n",
      "  Building wheel for iftools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for iftools: filename=iftools-0.1-py3-none-any.whl size=6442 sha256=b05d4df0e5835eabe4d8facccbc907c436f7f77235bc990446f5201d512eceb0\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-un91drjg/wheels/d8/64/88/5fdb197036df798ef14bcc865874e16890aaa398704495fc75\n",
      "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=b532fbcfbb4d8ac65b6a5c2308f34ada093542905cce9a8fc128c5de49082b8e\n",
      "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
      "  Building wheel for torch_geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for torch_geometric: filename=torch_geometric-2.3.1-py3-none-any.whl size=910454 sha256=bce3f5ab5969ad5f7daddbf08f64b29b17f27ea33ae4b8bb82e740cbfe796d45\n",
      "  Stored in directory: /root/.cache/pip/wheels/ac/dc/30/e2874821ff308ee67dcd7a66dbde912411e19e35a1addda028\n",
      "Successfully built iftools fire torch_geometric\n",
      "Installing collected packages: fire, torch_geometric, iftools\n",
      "Successfully installed fire-0.5.0 iftools-0.1 torch_geometric-2.3.1\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1iqF9IhdQS9ICKpkjnoFgTIMwa-ULtSGx\n",
      "To: /content/if-graph-train.h5\n",
      "100% 6.49G/6.49G [01:02<00:00, 104MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=16j9m8kc6gXs_3qbB-Ta2xEPTwdQTh0r3\n",
      "To: /content/if-graph-test.h5\n",
      "100% 1.18G/1.18G [00:11<00:00, 102MB/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/drinkingkazu/ssi_if\n",
    "! download_if_dataset.py --challenge=graph --flavor=train\n",
    "! download_if_dataset.py --challenge=graph --flavor=test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b76391-1de4-4b96-af66-c5da15f4c72d",
   "metadata": {
    "id": "74b76391-1de4-4b96-af66-c5da15f4c72d"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.multiprocessing.set_start_method('spawn')\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "import numpy as np\n",
    "SEED=42\n",
    "_ = np.random.seed(SEED)\n",
    "_ = torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5372a7c6-6a22-4532-80d7-28913a44fb58",
   "metadata": {
    "id": "5372a7c6-6a22-4532-80d7-28913a44fb58"
   },
   "source": [
    "## Shower Geometric Features `Dataset` and `DataLoader`\n",
    "The dataset returns a PyTorch Geometric object with the following attributes:\n",
    "* `x`: A `(C, 16)` tensor of node features;\n",
    "* `edge_index`: a `(2, E)` edge incidence matrix;\n",
    "* `edge_attr`: a `(E, 19)` tensor of edge features;\n",
    "* `y`: a `(C)` vector of node labels (primary IDs: 1 if primary, 0 if not);\n",
    "* `edge_label`: a `(E)` vector of edge labels (1 if connects two nodes in the same group, 0 otherwise);\n",
    "* `index`: a scalar representing the entry indices;\n",
    "* `C`: The number of \"clusters\" (nodes);\n",
    "* `E`: The number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8a8964-3303-42b9-b58e-c93b438bdce3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2a8a8964-3303-42b9-b58e-c93b438bdce3",
    "outputId": "4028514a-87e4-4aef-b14a-3981066ce257"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "from iftool.gnn_challenge import ShowerFeatures\n",
    "datapath = 'if-graph-train.h5'\n",
    "train_data = ShowerFeatures(file_path = datapath)\n",
    "\n",
    "from torch_geometric.loader import DataLoader as GraphDataLoader\n",
    "train_loader = GraphDataLoader(train_data,\n",
    "                               shuffle = True,\n",
    "                               num_workers = 4,\n",
    "                               batch_size = 64\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8dd15-d503-4a8f-a095-9227e88f87ca",
   "metadata": {
    "id": "1fb8dd15-d503-4a8f-a095-9227e88f87ca"
   },
   "source": [
    "# Model Choice\n",
    "The design of model will make use of both `MessagePassing` and iterative \"pruning\" to build a new graph that is more sparse and approaches the true connections. Each block of `MP` aims to update the edge features and score an edge if it should be connected or disconnected. The iterative pruning will then make use of this scoring to connect edges in order of highest to lowest score while maintaining a non-increasing cross entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69963022-435c-4c44-8679-97d0615e011b",
   "metadata": {
    "id": "69963022-435c-4c44-8679-97d0615e011b"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch.nn import Sequential, Linear, ReLU\n",
    "from torch_geometric.nn import MessagePassing, BatchNorm\n",
    "\n",
    "class EdgeConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__(aggr='max') # Max aggregation.\n",
    "        self.mlp = Sequential(Linear(2 * in_channels, out_channels),\n",
    "                                     ReLU(),\n",
    "                                     Linear(out_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \"\"\"\n",
    "        x has shape [N, in_channels]\n",
    "        edge_index has shape [2, E]\n",
    "        \"\"\"\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j):\n",
    "        \"\"\"\n",
    "        x_i, x_j both have the shape [E, in_channels].\n",
    "        \"\"\"\n",
    "        tmp = torch.cat([x_i, x_j], dim=1) # tmp has shape [E, 2 * in_channels]\n",
    "        return self.mlp(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7158cc93-e90f-41a8-a743-12d9e054d59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnionFind():\n",
    "    def __init__(self, num_nodes):\n",
    "        self.parent = torch.zeros(num_nodes, dtype=torch.int)\n",
    "        self.size = torch.ones(num_nodes, dtype=torch.int)\n",
    "        for i in range(num_nodes):\n",
    "            self.parent[i] = i\n",
    "\n",
    "    def find(self, i):\n",
    "        while (self.parent[i] != i):\n",
    "            self.parent[i] = self.parent[self.parent[i]]\n",
    "            i = self.parent[i]\n",
    "        return i\n",
    "\n",
    "    def union(self, i, j):\n",
    "        # Use the roots for nodes i and j\n",
    "        i = self.find(i)\n",
    "        j = self.find(j)\n",
    "\n",
    "        # If the same, nothing to unify.\n",
    "        if i == j:\n",
    "            return\n",
    "\n",
    "        # Keep it so that node i always has a larger size\n",
    "        if self.size[i] < self.size[j]:\n",
    "            tmp = i\n",
    "            i = j\n",
    "            j = tmp\n",
    "\n",
    "        self.parent[j] = i\n",
    "        self.size[i] += self.size[j]\n",
    "\n",
    "class IterPrune(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IterPrune, self).__init__()\n",
    "\n",
    "    def _same_partition(self, g, i, j):\n",
    "        \"\"\"\n",
    "        g is of type UnionFind.\n",
    "        i, j are nodes.\n",
    "        \"\"\"\n",
    "        return g.find(i) == g.find(j)\n",
    "\n",
    "    def forward(self, scores):\n",
    "        \"\"\"\n",
    "        Takes the edge label scores as input and iteratively selects the\n",
    "        relevant edges that strictly lower the partition cross entropy.\n",
    "\n",
    "        Returns the updated edge scores (1 or 0) and the connected edge index.\n",
    "        \"\"\"\n",
    "        score_mask = scores.detach().clone()\n",
    "\n",
    "        g = UnionFind(score_mask.shape[0]) # Used to check that two nodes are in the same subgraph\n",
    "        L = 0\n",
    "        kept_edge_count = 0\n",
    "        pruned_edges = torch.zeros(edge_index.shape) # Slightly large, slice later.\n",
    "        while (new_L <= L):\n",
    "            max_edge = torch.argmax(score_mask)\n",
    "            I,J = edge_index[0, max_edge], edge_index[1, max_edge]\n",
    "            g.union(I,J) # Unify nodes I and J to the same subgraph\n",
    "            score_mask[max_edge] = -1 # Don't look at this score in later iterations\n",
    "\n",
    "            new_L = 0\n",
    "            for edge_idx, score in enumerate(scores):\n",
    "                i,j = edge_index[0, edge_idx], edge_index[1, edge_idx]\n",
    "                if self._same_partition(g,i,j):\n",
    "                    new_L += torch.log(score)\n",
    "                else:\n",
    "                    new_L += torch.log(1 - score)\n",
    "            new_L *= -1\n",
    "            if (new_L < L):\n",
    "                pruned_edges[0, kept_edge_count] = I\n",
    "                pruned_edges[1, kept_edge_count] = J\n",
    "                kept_edge_count += 1\n",
    "                L = new_L\n",
    "\n",
    "        # Get the new scoring based on the iterations\n",
    "        connected_edges = torch.where(score_mask == -1)\n",
    "        disconnected_edges = torch.where(score_mask != -1)\n",
    "        scores[connected_edges] = 1\n",
    "        scores[disconnected_edges] = 0\n",
    "        return scores, pruned_edges[:,:kept_edge_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19860b19-0314-48a6-a5cd-eba2252bb381",
   "metadata": {
    "id": "19860b19-0314-48a6-a5cd-eba2252bb381"
   },
   "outputs": [],
   "source": [
    "class Node2Edge(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Node2Edge, self).__init__()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return x[edge_index[0]] - x[edge_index[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54953555-4d42-4eaf-853b-3e32576152e1",
   "metadata": {
    "id": "54953555-4d42-4eaf-853b-3e32576152e1"
   },
   "outputs": [],
   "source": [
    "class LostEdgePruning(torch.nn.Module):\n",
    "    def __init__(self, num_node_features):\n",
    "        super(LostEdgePruning, self).__init__()\n",
    "        self.batch_norm = BatchNorm(num_node_features)\n",
    "        self.node2edge = Node2Edge()\n",
    "        self.conv1 = EdgeConv(num_node_features, num_node_features//2)\n",
    "        self.conv2 = EdgeConv(num_node_features, num_node_features//2)\n",
    "        self.lin1 = Sequential(Linear(num_node_features//2, 1))\n",
    "        self.lin2 = Sequential(Linear(num_node_features//2, 1))\n",
    "        self.iter_prune = IterPrune()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x0, edge_index0 = data.x, data.edge_index\n",
    "        x0 = self.batch_norm(x0)\n",
    "        x = self.conv1(x, edge_index0)\n",
    "        x = self.lin1(x)\n",
    "        x = self.node2edge(x, edge_index)\n",
    "        x = F.sigmoid(x)\n",
    "        x1, edge_index1 = self.iter_prune(x)\n",
    "        x = self.conv2(x0, edge_index1)\n",
    "        x = self.lin2(x)\n",
    "        x = self.node2edge(x, edge_index1)\n",
    "        x = F.sigmoid(x)\n",
    "        x2, edge_index2 = self.iter_prune(x)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3baca7f-c4e1-43dc-b86c-4305b4ee1f8a",
   "metadata": {
    "id": "e3baca7f-c4e1-43dc-b86c-4305b4ee1f8a"
   },
   "source": [
    "# Training\n",
    "Start the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b8461c-7a92-49e3-9f63-1b0dc5748f81",
   "metadata": {
    "id": "71b8461c-7a92-49e3-9f63-1b0dc5748f81"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import BCELoss\n",
    "\n",
    "loss_fn = BCELoss()\n",
    "num_node_feats = 16\n",
    "gnn = LostEdgePruning(num_node_feats)\n",
    "gnn.to(device)\n",
    "opt = optim.Adam(gnn.parameters(), lr = 0.001)\n",
    "def train(model, num_epochs = 5):\n",
    "    model.train(True)\n",
    "    tot_iter = len(train_loader)\n",
    "\n",
    "    for ep in range(num_epochs):\n",
    "        running_loss, running_correct = 0, 0\n",
    "        for data_idx, data in enumerate(train_loader):\n",
    "            data.to(device)\n",
    "            inputs = data\n",
    "            labels = data.edge_label.reshape(-1,1).float()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if (data_idx % 50 == 0):\n",
    "                print(data_idx, loss.item())\n",
    "\n",
    "        epoch_loss = running_loss / tot_iter\n",
    "        print(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pgkiOhWvliEP",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "id": "pgkiOhWvliEP",
    "outputId": "3e41e7d0-87fe-47fe-90b2-b322504046d6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.6937949061393738\n",
      "50 0.6932360529899597\n",
      "100 0.6931782960891724\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-49e0ddb89e82>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-3771553ea5ff>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    278\u001b[0m                                                f\"but got {result}.\")\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'differentiable'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    139\u001b[0m                 state_steps)\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    142\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m     func(params,\n\u001b[0m\u001b[1;32m    282\u001b[0m          \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m          \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    389\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sqs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(gnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BDH1Y5ZHmTAw",
   "metadata": {
    "id": "BDH1Y5ZHmTAw"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
